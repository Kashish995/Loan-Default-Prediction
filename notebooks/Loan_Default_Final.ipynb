{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981e0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d5b899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148670, 34)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/loan_data.csv\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3be3bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "0    112031\n",
       "1     36639\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Status\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afc1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Status\", axis=1)\n",
    "y = df[\"Status\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338e1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.median(numeric_only=True))\n",
    "X = X.fillna(\"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e89c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148670, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149706a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcefae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [ 7328     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     22406\n",
      "           1       0.00      0.00      0.00      7328\n",
      "\n",
      "    accuracy                           0.75     29734\n",
      "   macro avg       0.38      0.50      0.43     29734\n",
      "weighted avg       0.57      0.75      0.65     29734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\Loan-Default-Prediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\Loan-Default-Prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\Loan-Default-Prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\Loan-Default-Prediction\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3de535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11597 10809]\n",
      " [ 1698  5630]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.52      0.65     22406\n",
      "           1       0.34      0.77      0.47      7328\n",
      "\n",
      "    accuracy                           0.58     29734\n",
      "   macro avg       0.61      0.64      0.56     29734\n",
      "weighted avg       0.74      0.58      0.61     29734\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\Loan-Default-Prediction\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_bal = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "model_bal.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bal = model_bal.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_bal))\n",
    "print(classification_report(y_test, y_pred_bal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dace9d",
   "metadata": {},
   "source": [
    "# Loan Default Prediction Project\n",
    "\n",
    "Dataset size: 148,670 records  \n",
    "Problem: Binary classification (Default vs Non-default)\n",
    "\n",
    "Key Challenges:\n",
    "- Class imbalance (majority = non-default)\n",
    "- Missing values\n",
    "- Categorical variables\n",
    "\n",
    "Techniques Used:\n",
    "- Median imputation\n",
    "- One-hot encoding\n",
    "- Logistic Regression\n",
    "- Class balancing\n",
    "\n",
    "Result:\n",
    "Balanced model significantly improved recall for default class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee55754",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8540efdf",
   "metadata": {},
   "source": [
    "venv/\n",
    "__pycache__/\n",
    ".ipynb_checkpoints/\n",
    "*.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752a85e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d279979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19732  2674]\n",
      " [ 2117  5211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89     22406\n",
      "           1       0.66      0.71      0.69      7328\n",
      "\n",
      "    accuracy                           0.84     29734\n",
      "   macro avg       0.78      0.80      0.79     29734\n",
      "weighted avg       0.84      0.84      0.84     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a69968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29734, 56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f854f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118936\n",
      "29734\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9334fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (118936, 56)\n",
      "Test shape: (29734, 56)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d55cde3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique train rows: 118936\n",
      "Unique test rows: 29734\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique train rows:\", len(X_train))\n",
    "print(\"Unique test rows:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b546bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b3d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'year', 'loan_limit', 'Gender', 'approv_in_adv', 'loan_type',\n",
      "       'loan_purpose', 'Credit_Worthiness', 'open_credit',\n",
      "       'business_or_commercial', 'loan_amount', 'rate_of_interest',\n",
      "       'Interest_rate_spread', 'Upfront_charges', 'term', 'Neg_ammortization',\n",
      "       'interest_only', 'lump_sum_payment', 'property_value',\n",
      "       'construction_type', 'occupancy_type', 'Secured_by', 'total_units',\n",
      "       'income', 'credit_type', 'Credit_Score', 'co-applicant_credit_type',\n",
      "       'age', 'submission_of_application', 'LTV', 'Region', 'Security_Type',\n",
      "       'Status', 'dtir1'],\n",
      "      dtype='str')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e05ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status              1.000000\n",
      "dtir1               0.078083\n",
      "LTV                 0.038895\n",
      "rate_of_interest    0.022957\n",
      "Credit_Score        0.004004\n",
      "ID                  0.001703\n",
      "term               -0.000240\n",
      "Upfront_charges    -0.019138\n",
      "loan_amount        -0.036825\n",
      "property_value     -0.048864\n",
      "Name: Status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "corr = df.corr(numeric_only=True)[\"Status\"].sort_values(ascending=False)\n",
    "print(corr.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e57faebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [    0  7328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22406\n",
      "           1       1.00      1.00      1.00      7328\n",
      "\n",
      "    accuracy                           1.00     29734\n",
      "   macro avg       1.00      1.00      1.00     29734\n",
      "weighted avg       1.00      1.00      1.00     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a80402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118936 29734\n",
      "29734\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))\n",
    "print(len(rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eed45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status in X? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Status in X?\", \"Status\" in X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dacd3028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in full dataset: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate rows in full dataset:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "485a6d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap rows: 0\n"
     ]
    }
   ],
   "source": [
    "train_hash = set(map(tuple, X_train.values))\n",
    "test_hash = set(map(tuple, X_test.values))\n",
    "\n",
    "print(\"Overlap rows:\", len(train_hash.intersection(test_hash)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afd86161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [0 1]\n",
      "Unique values in rf_pred: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_test:\", np.unique(y_test))\n",
    "print(\"Unique values in rf_pred:\", np.unique(rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77117674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are predictions identical to y_test? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Are predictions identical to y_test?\", np.array_equal(rf_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de498a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [    0  7328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22406\n",
      "           1       1.00      1.00      1.00      7328\n",
      "\n",
      "    accuracy                           1.00     29734\n",
      "   macro avg       1.00      1.00      1.00     29734\n",
      "weighted avg       1.00      1.00      1.00     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de0efa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2393304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train equals full X? False\n",
      "Test equals full X? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Train equals full X?\", X_train.equals(X))\n",
    "print(\"Test equals full X?\", X_test.equals(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3559276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential perfect separator: construction_type\n",
      "Status                  0      1\n",
      "construction_type               \n",
      "mh                      0     33\n",
      "sb                 112031  36606\n",
      "Potential perfect separator: Secured_by\n",
      "Status           0      1\n",
      "Secured_by               \n",
      "home        112031  36606\n",
      "land             0     33\n",
      "Potential perfect separator: Security_Type\n",
      "Status              0      1\n",
      "Security_Type               \n",
      "Indriect            0     33\n",
      "direct         112031  36606\n",
      "Potential perfect separator: Status\n",
      "Status       0      1\n",
      "Status               \n",
      "0       112031      0\n",
      "1            0  36639\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].nunique() == 2:\n",
    "        table = pd.crosstab(X[col], y)\n",
    "        if table.min().min() == 0:\n",
    "            print(\"Potential perfect separator:\", col)\n",
    "            print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9a36f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Status</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Security_Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Indriect</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct</th>\n",
       "      <td>112031</td>\n",
       "      <td>36606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Status              0      1\n",
       "Security_Type               \n",
       "Indriect            0     33\n",
       "direct         112031  36606"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df[\"construction_type\"], df[\"Status\"])\n",
    "pd.crosstab(df[\"Secured_by\"], df[\"Status\"])\n",
    "pd.crosstab(df[\"Security_Type\"], df[\"Status\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4eac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Status\", \"construction_type\", \"Secured_by\", \"Security_Type\"], axis=1)\n",
    "y = df[\"Status\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f4f679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (148670, 30)\n"
     ]
    }
   ],
   "source": [
    "# Remove leakage columns\n",
    "leakage_cols = [\"construction_type\", \"Secured_by\", \"Security_Type\"]\n",
    "\n",
    "X = df.drop([\"Status\"] + leakage_cols, axis=1)\n",
    "y = df[\"Status\"]\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19136417",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.median(numeric_only=True))\n",
    "X = X.fillna(\"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "673d7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: (148670, 53)\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)\n",
    "print(\"Encoded shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89726b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118936, 53) (29734, 53)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "239aaf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19726  2680]\n",
      " [ 2121  5207]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89     22406\n",
      "           1       0.66      0.71      0.68      7328\n",
      "\n",
      "    accuracy                           0.84     29734\n",
      "   macro avg       0.78      0.80      0.79     29734\n",
      "weighted avg       0.84      0.84      0.84     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "723f127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [    0  7328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22406\n",
      "           1       1.00      1.00      1.00      7328\n",
      "\n",
      "    accuracy                           1.00     29734\n",
      "   macro avg       1.00      1.00      1.00     29734\n",
      "weighted avg       1.00      1.00      1.00     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49460704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status                               1.000000\n",
      "credit_type_EQUI                     0.592168\n",
      "Neg_ammortization_neg_amm            0.155835\n",
      "co-applicant_credit_type_EXP         0.144239\n",
      "submission_of_application_to_inst    0.117391\n",
      "loan_type_type2                      0.092550\n",
      "dtir1                                0.082432\n",
      "age_Missing                          0.064179\n",
      "Gender_Sex Not Available             0.053336\n",
      "loan_limit_ncf                       0.053332\n",
      "LTV                                  0.042656\n",
      "Region_south                         0.040051\n",
      "approv_in_adv_nopre                  0.036062\n",
      "Credit_Worthiness_l2                 0.034875\n",
      "loan_purpose_p2                      0.029369\n",
      "Name: Status, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check correlation again AFTER removing leakage columns\n",
    "corr = pd.concat([X, y], axis=1).corr(numeric_only=True)[\"Status\"].sort_values(ascending=False)\n",
    "\n",
    "print(corr.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "759122b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential separator: age_Missing\n",
      "Status            0      1\n",
      "age_Missing               \n",
      "False        112031  36439\n",
      "True              0    200\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].nunique() < 10:\n",
    "        table = pd.crosstab(X[col], y)\n",
    "        if (table == 0).any().any():\n",
    "            print(\"Potential separator:\", col)\n",
    "            print(table)\n",
    "            print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1497a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop: []\n",
      "New shape after dropping: (148670, 52)\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns that were created from \"Missing\" category\n",
    "missing_cols = [col for col in X.columns if \"Missing\" in col]\n",
    "\n",
    "print(\"Columns to drop:\", missing_cols)\n",
    "\n",
    "X = X.drop(columns=missing_cols)\n",
    "\n",
    "print(\"New shape after dropping:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4274e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbc55803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [    0  7328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22406\n",
      "           1       1.00      1.00      1.00      7328\n",
      "\n",
      "    accuracy                           1.00     29734\n",
      "   macro avg       1.00      1.00      1.00     29734\n",
      "weighted avg       1.00      1.00      1.00     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fed7005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"recall\",   # IMPORTANT â†’ banks care about catching defaults\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2c0cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22406     0]\n",
      " [    0  7328]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22406\n",
      "           1       1.00      1.00      1.00      7328\n",
      "\n",
      "    accuracy                           1.00     29734\n",
      "   macro avg       1.00      1.00      1.00     29734\n",
      "weighted avg       1.00      1.00      1.00     29734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37d46786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\user\\\\OneDrive\\\\Desktop\\\\Loan-Default-Prediction\\\\notebooks'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2fd1331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analysis.ipynb', 'Loan_Default_Final.ipynb', 'loan_default_model.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac0f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
